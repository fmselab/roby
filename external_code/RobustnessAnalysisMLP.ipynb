{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gothic-perspective",
   "metadata": {},
   "source": [
    "## Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surface-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "noted-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mode: DEBUG = 1 => Print all the info, DEBUG = 0 => Skip printing\n",
    "DEBUG = False\n",
    "\n",
    "# \"./thesis/checkpoints/chkp_augmentation_mt.h5\" -> MIXTURE TECHNIQUES\n",
    "# \"./thesis/checkpoints/chkp_40_final.h5\" -> ORIGINAL NET\n",
    "# \"./thesis/checkpoints/chkp_augmentation_awn.h5\" -> DATA AUGMENTATION\n",
    "# \"./thesis/checkpoints/chkp_augmentation_awn_p.h5\" -> DATA AUGMENTATION - PARALLEL NET [SET MODE = 1]\n",
    "\n",
    "# Define the models to be used (None if no model must be used)\n",
    "modelName = \"./thesis/checkpoints/chkp_40_final.h5\"\n",
    "model1Name = \"./thesis/checkpoints/chkp_augmentation_awn_p.h5\"\n",
    "\n",
    "# Define whether to parallelize networks: MODE = 0 => only the first model, MODE = 1 => Use also the parallel network (model1)\n",
    "MODE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-refrigerator",
   "metadata": {},
   "source": [
    "### Function to be used for computing the parameters of the curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "committed-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_params(curve):\n",
    "    val_0 = np.mean(curve[55-5:55+5])\n",
    "    val_1 = np.mean(curve[100-10:100+10])\n",
    "    val_2 = np.mean(curve[200-10:200+10])\n",
    "    val_3 = np.mean(curve[350-10:350+10])\n",
    "    val_4 = np.mean(curve[630-10:630+10])\n",
    "    \n",
    "    return val_0, val_1, val_2, val_3, val_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-sailing",
   "metadata": {},
   "source": [
    "## Dataset MNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scientific-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Import the complete dataset\n",
    "with open('./thesis/XX_40.pkl', 'rb') as f:\n",
    "    XX = pickle.load(f)\n",
    "\n",
    "if DEBUG is True:\n",
    "    print (XX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "structured-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = np.zeros((len(XX), ), dtype=bool)\n",
    "filters[:13650 + 8000] = np.ones((13650 + 8000, ))\n",
    "\n",
    "if DEBUG is True:\n",
    "    np.sum(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "heard-roller",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = XX[filters].astype(np.float32)\n",
    "\n",
    "if DEBUG is True:\n",
    "    print(X.shape)\n",
    "    print(X[3000:5000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "close-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data in test dataset\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "innocent-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset, in order to obtain the test and validation dataset\n",
    "train_ts = int(X.shape[0]*0.6)\n",
    "valid_ts = int(X.shape[0]*0.8)\n",
    "\n",
    "x_train = X[:train_ts, :-2]\n",
    "y_train = X[:train_ts, -2:]\n",
    "\n",
    "x_valid = X[train_ts:valid_ts, :-2]\n",
    "y_valid = X[train_ts:valid_ts, -2:]\n",
    "\n",
    "x_test = X[valid_ts:, :-2]\n",
    "y_test = X[valid_ts:, -2:]\n",
    "\n",
    "# minmax normalization\n",
    "xmin = np.min(x_train, axis=0)\n",
    "xmax = np.max(x_train, axis=0)\n",
    "\n",
    "x_train = (x_train - xmin) / (xmax - xmin)\n",
    "x_valid = (x_valid - xmin) / (xmax - xmin)\n",
    "x_test  = (x_test  - xmin) / (xmax - xmin)\n",
    "\n",
    "if DEBUG is True:\n",
    "    print (x_test)\n",
    "    \n",
    "ymax = np.max(y_train, axis=0)\n",
    "ymin = np.min(y_train, axis=0)\n",
    "\n",
    "y_train = (y_train - ymin) / (ymax - ymin)\n",
    "y_valid = (y_valid - ymin) / (ymax - ymin)\n",
    "y_test  = (y_test  - ymin) / (ymax - ymin)\n",
    "\n",
    "if DEBUG is True:\n",
    "    print('normalization parameters')\n",
    "    print('xmin: \\t' + str(xmin))\n",
    "    print('xmax: \\t' + str(xmax))\n",
    "    print('ymin: \\t' + str(ymin))\n",
    "    print('ymax: \\t' + str(ymax))\n",
    "    print('data shapes')\n",
    "    print(x_train.shape)\n",
    "    print(x_valid.shape)\n",
    "    print(x_test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advised-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to be used for denormalizing data given by the model\n",
    "def denormalize(y_pred):\n",
    "    return y_pred*(ymax-ymin) + ymin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-hollywood",
   "metadata": {},
   "source": [
    "## Model robustness functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mental-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_absolute_error as keras_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fabulous-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wighted MAE function\n",
    "def weightedMAE(y_true, y_pred):\n",
    "    mae = keras_mae(y_true, y_pred)\n",
    "    return mae*( (1 - K.mean(y_true))**2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "equipped-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical MAE function\n",
    "def mae(y_true, y_pred):\n",
    "    errors = np.mean(np.abs((y_true - y_pred)))\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceramic-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE Function\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    errors = np.abs((y_true - y_pred) / (y_true + 0.00001)) * 100\n",
    "    return np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "future-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APE Function\n",
    "def absolute_percentage_error(y_true, y_pred): \n",
    "    errors = np.abs((y_true - y_pred) / (y_true + 0.00001)) * 100\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-equality",
   "metadata": {},
   "source": [
    "### Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "color-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "model = keras.models.load_model(modelName, custom_objects={'weightedMAE': weightedMAE})\n",
    "\n",
    "if (DEBUG is True):\n",
    "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "if model1Name is not None:\n",
    "    model1 = keras.models.load_model(model1Name, custom_objects={'weightedMAE': weightedMAE})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-professor",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "patient-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Open the pickle files in order to have the curves to be altered\n",
    "with open('./thesis/X_robustness.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "    \n",
    "with open('./thesis/onde_robustness.pkl', 'rb') as f:\n",
    "    onde_raw = pickle.load(f)\n",
    "\n",
    "if DEBUG is True:\n",
    "    print(X.shape)\n",
    "    print(onde_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "latest-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataframe\n",
    "columns = ['TBlood', 'v0', 'v1', 'v2', 'v3', 'v4', 'pO2_ABL1_37', 'pO2_ABL1']\n",
    "df = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "if DEBUG is True:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-begin",
   "metadata": {},
   "source": [
    "## Robustness functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-collect",
   "metadata": {},
   "source": [
    "### 1. UU Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "satisfactory-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def integrand_h(x, x0, err):\n",
    "    return err[int(x)]/x0\n",
    "\n",
    "def UU_robustness(mape, theta, x0):\n",
    "    err = theta-mape\n",
    "    h = np.heaviside(err,0)\n",
    "    \n",
    "    r = quad(integrand_h, 0, x0, args=(x0,h))\n",
    "    return r[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-degree",
   "metadata": {},
   "source": [
    "### 2. UL Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "available-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def integrand_b(x, x0, err):\n",
    "    if (err[int(x)] > 0):\n",
    "        return err[int(x)]/x0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def UL_robustness(mape, theta, x0):\n",
    "    err = theta-mape\n",
    "    \n",
    "    r = quad(integrand_b, 0, x0, args=(x0,err)) \n",
    "    return r[0] / theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-preview",
   "metadata": {},
   "source": [
    "### 3. LU Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "organizational-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def integrand_w(x, x0, err):\n",
    "    return err[int(x)] * (x0 - x)\n",
    "\n",
    "def LU_robustness(mape, theta, x0):\n",
    "    err = theta-mape\n",
    "    h = np.heaviside(err,0)\n",
    "    \n",
    "    r = quad(integrand_w, 0, x0, args=(x0,h)) \n",
    "    return r[0] / (0.5 * x0 * x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-niagara",
   "metadata": {},
   "source": [
    "### 4. LL Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adapted-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def integrand_LL(x, x0, err):\n",
    "    if (err[int(x)] > 0):\n",
    "        return err[int(x)] * (x0 - x)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def LL_robustness(mape, theta, x0):\n",
    "    err = theta-mape\n",
    "    \n",
    "    r = quad(integrand_LL, 0, x0, args=(x0,err)) \n",
    "    return r[0] / (0.5 * theta * x0 * x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-steps",
   "metadata": {},
   "source": [
    "## Robustness ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "effective-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold\n",
    "theta = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-scheduling",
   "metadata": {},
   "source": [
    "### 1. Cut of the end of the curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "progressive-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Configuration params\n",
    "l_A = 620\n",
    "u_A = 640\n",
    "theta = 10\n",
    "\n",
    "# Function to be used for cutting the end of the curves\n",
    "def curve_end_cut(onde_raw, start):\n",
    "    onde_new = np.copy(onde_raw)\n",
    "    onde_new[:,start:]=0.0\n",
    "    return onde_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "collectible-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteration on all the curves and data analysis\n",
    "\n",
    "# Prepare the resulting vectors as empty ones \n",
    "mape = np.empty(((u_A-l_A)+1, 2), dtype=np.float32)\n",
    "\n",
    "# Apply all the levels of alteration\n",
    "for j in range((u_A-l_A)+1):\n",
    "    \n",
    "    # Alter all the curves\n",
    "    onde_new = curve_end_cut(onde_raw, u_A-j)    \n",
    "\n",
    "    # Compute the parameters (5 average values) from each curve\n",
    "    params = np.empty((len(onde_new), 5), dtype=np.float32)\n",
    "    for i in range(len(onde_new)):\n",
    "        try:\n",
    "            params[i] = np.array(compute_params(onde_new[i]))\n",
    "            assert np.any(np.isnan(params[i])) == False\n",
    "        except:\n",
    "            print(\"Parameter \" + str(i) + \" cannot be computed\")\n",
    "            continue\n",
    "            \n",
    "    # Test set + normalization\n",
    "    new_data  = np.concatenate([df.TBlood.values.reshape(-1,1),params], axis = 1)\n",
    "    test  = (new_data  - xmin) / (xmax - xmin) \n",
    "\n",
    "    # Prediction using the models\n",
    "    if MODE == 0:\n",
    "        pred = model.predict(test)\n",
    "        y_pred_denorm  = denormalize(pred)\n",
    "    else:\n",
    "        # Using the parallel network as well\n",
    "        y_pred_t0 = model.predict(test)\n",
    "        y_pred_t1 = model1.predict(test)\n",
    "\n",
    "        y_pred_t0_denorm  = denormalize(y_pred_t0)\n",
    "        y_pred_t1_denorm  = denormalize(y_pred_t1)\n",
    "        y_pred_denorm = (y_pred_t0_denorm + y_pred_t1_denorm)/2\n",
    "\n",
    "    # Save the true values for evaluation\n",
    "    pO2_true = np.concatenate([df.pO2_ABL1_37.values.reshape(-1,1), df.pO2_ABL1.values.reshape(-1,1)], axis=1)\n",
    "   \n",
    "    # Compute the MAPE\n",
    "    mape[j,0]=mean_absolute_percentage_error(pO2_true[:, 0], y_pred_denorm[:, 0])\n",
    "    mape[j,1]=mean_absolute_percentage_error(pO2_true[:, 1], y_pred_denorm[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abandoned-torture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UU Robustness [Cut of the end of the curve - Current pO2]: 0.14285714285714288\n",
      "UL Robustness [Cut of the end of the curve - Current pO2]: 0.07260609127226521\n",
      "LU Robustness [Cut of the end of the curve - Current pO2]: 0.2653061224415068\n",
      "LL Robustness [Cut of the end of the curve - Current pO2]: 0.13650776782339885\n",
      "UU Robustness [Cut of the end of the curve - pO2 at 37°]: 0.1904761904761903\n",
      "UL Robustness [Cut of the end of the curve - pO2 at 37°]: 0.09020376226798277\n",
      "LU Robustness [Cut of the end of the curve - pO2 at 37°]: 0.34467120183055056\n",
      "LL Robustness [Cut of the end of the curve - pO2 at 37°]: 0.16696992813174405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-f7376d6114f0>:12: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  r = quad(integrand_b, 0, x0, args=(x0,err))\n"
     ]
    }
   ],
   "source": [
    "# Estimating the robustness w.r.t. Current pO2\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,1]\n",
    "real = mape[:,1]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Cut of the end of the curve - Current pO2]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Cut of the end of the curve - Current pO2]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Cut of the end of the curve - Current pO2]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Cut of the end of the curve - Current pO2]: '+str(ll))\n",
    "\n",
    "\n",
    "# Estimating the robustness w.r.t. pO2 at 37°\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,0]\n",
    "real = mape[:,0]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Cut of the end of the curve - pO2 at 37°]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Cut of the end of the curve - pO2 at 37°]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Cut of the end of the curve - pO2 at 37°]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Cut of the end of the curve - pO2 at 37°]: '+str(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cloudy-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the Current pO2\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(range(640,619,-1)),mape[:,1], marker='x', color='blue', )\n",
    "    plt.xlabel('maximum value cancelled')\n",
    "    plt.xticks(np.array(range(640,619,-1)))\n",
    "    plt.yticks(np.array(range(-5,50,5)))\n",
    "    plt.ylabel('MAPE error - current po2')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,1], c='green', label = 'nominal MAPE')\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    ax.invert_xaxis()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "gentle-brook",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the pO2 at 37°\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(range(640,619,-1)),mape[:,0], marker='x', color='blue', )\n",
    "    plt.xlabel('maximum value cancelled')\n",
    "    plt.xticks(np.array(range(640,619,-1)))\n",
    "    plt.yticks(np.array(range(-5,50,5)))\n",
    "    plt.ylabel('MAPE error - pO2 at 37°')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,0], c='green', label = 'nominal MAPE')\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    ax.invert_xaxis()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-distribution",
   "metadata": {},
   "source": [
    "### 2. Clock Offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bound-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration params\n",
    "l_A = 0\n",
    "u_A = 30\n",
    "theta = 10\n",
    "\n",
    "# Function to be used for introducing a clock offset\n",
    "def clock_offset(onde_raw, offset):\n",
    "    onde_new = np.copy(onde_raw)\n",
    "    end = onde_new.shape[1]\n",
    "    for i in range(end-offset):\n",
    "        onde_new[:,end-1-i]=onde_new[:,end-1-i-offset]\n",
    "    onde_new[:,:offset]=0\n",
    "    return onde_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "suited-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteration on all the curves and data analysis\n",
    "\n",
    "# Prepare the resulting vectors as empty ones\n",
    "mape = np.empty(((u_A-l_A) + 1, 2), dtype=np.float32)\n",
    "\n",
    "# Apply all the levels of alteration\n",
    "for j in range((u_A-l_A) + 1):\n",
    "    onde_new = np.copy(onde_raw)\n",
    "\n",
    "    # Alter all the curves\n",
    "    onde_new = clock_offset(onde_new, j)  \n",
    "\n",
    "    # Compute the parameters (5 average values) from each curve\n",
    "    params = np.empty((len(onde_new), 5), dtype=np.float32)\n",
    "    for i in range(len(onde_new)):\n",
    "        try:\n",
    "            params[i] = np.array(compute_params(onde_new[i]))\n",
    "            assert np.any(np.isnan(params[i])) == False\n",
    "        except:\n",
    "            print(\"Parameter \" + str(i) + \" cannot be computed\")\n",
    "            continue\n",
    "\n",
    "    # Test set + normalization\n",
    "    new_data  = np.concatenate([df.TBlood.values.reshape(-1,1),params], axis = 1)\n",
    "    test  = (new_data  - xmin) / (xmax - xmin)    \n",
    "\n",
    "    # Prediction using the models\n",
    "    if MODE == 0:\n",
    "        pred = model.predict(test)\n",
    "        y_pred_denorm  = denormalize(pred)\n",
    "    else:\n",
    "        # Using the parallel network as well\n",
    "        y_pred_t0 = model.predict(test)\n",
    "        y_pred_t1 = model1.predict(test)\n",
    "\n",
    "        y_pred_t0_denorm  = denormalize(y_pred_t0)\n",
    "        y_pred_t1_denorm  = denormalize(y_pred_t1)\n",
    "        y_pred_denorm = (y_pred_t0_denorm + y_pred_t1_denorm)/2\n",
    "\n",
    "    # Save the true values for evaluation\n",
    "    pO2_true = np.concatenate([df.pO2_ABL1_37.values.reshape(-1,1), df.pO2_ABL1.values.reshape(-1,1)], axis=1)\n",
    "   \n",
    "    # Compute the MAPE\n",
    "    mape[j,0]=mean_absolute_percentage_error(pO2_true[:, 0], y_pred_denorm[:, 0])\n",
    "    mape[j,1]=mean_absolute_percentage_error(pO2_true[:, 1], y_pred_denorm[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "amino-preservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UU Robustness [Clock offset - Current pO2]: 0.8709677419354835\n",
      "UL Robustness [Clock offset - Current pO2]: 0.40099386716899754\n",
      "LU Robustness [Clock offset - Current pO2]: 0.9833506764631899\n",
      "LL Robustness [Clock offset - Current pO2]: 0.5231721099564837\n",
      "UU Robustness [Clock offset - pO2 at 37°]: 0.8709677419354835\n",
      "UL Robustness [Clock offset - pO2 at 37°]: 0.38599579974231485\n",
      "LU Robustness [Clock offset - pO2 at 37°]: 0.9833506764631899\n",
      "LL Robustness [Clock offset - pO2 at 37°]: 0.5171704632403897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-f7376d6114f0>:12: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  r = quad(integrand_b, 0, x0, args=(x0,err))\n"
     ]
    }
   ],
   "source": [
    "# Estimating the robustness w.r.t. Current pO2\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,1]\n",
    "real = mape[:,1]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Clock offset - Current pO2]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Clock offset - Current pO2]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Clock offset - Current pO2]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Clock offset - Current pO2]: '+str(ll))\n",
    "\n",
    "# Estimating the robustness w.r.t. pO2 at 37°\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,0]\n",
    "real = mape[:,0]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Clock offset - pO2 at 37°]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Clock offset - pO2 at 37°]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Clock offset - pO2 at 37°]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Clock offset - pO2 at 37°]: '+str(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hearing-writing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the Current pO2\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(range(0,31,1)),mape[:,1], marker='x', color='blue', )\n",
    "    plt.xlabel('Offset')\n",
    "    plt.xticks(np.array(range(0,31,2)))\n",
    "    plt.yticks(np.array(range(0,30,2)))\n",
    "    plt.ylabel('MAPE error - current po2')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,1], c='green', label = 'MAPE_0')\n",
    "\n",
    "    SMALL_SIZE = 8\n",
    "    MEDIUM_SIZE = 10\n",
    "    BIGGER_SIZE = 25\n",
    "\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "    ax = c.axes\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "animal-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the Current pO2\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(range(0,31,1)),mape[:,0], marker='x', color='blue', )\n",
    "    plt.xlabel('Offset')\n",
    "    plt.xticks(np.array(range(0,31,2)))\n",
    "    plt.yticks(np.array(range(0,30,2)))\n",
    "    plt.ylabel('MAPE error - pO2 at 37°')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,0], c='green', label = 'MAPE_0')\n",
    "\n",
    "    SMALL_SIZE = 8\n",
    "    MEDIUM_SIZE = 10\n",
    "    BIGGER_SIZE = 25\n",
    "\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-dimension",
   "metadata": {},
   "source": [
    "### 3. Cut of the peak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "prospective-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration params\n",
    "l_A = 1300\n",
    "u_A = 4000\n",
    "theta = 10\n",
    "step = -10\n",
    "\n",
    "# Function to be used for introducing a cut of the peak alteration\n",
    "def peak_cut(onde_raw, threshold):\n",
    "    onde_new = np.copy(onde_raw)\n",
    "    for i in range(onde_new.shape[1]):\n",
    "        index = np.where(onde_new[:,i]>threshold)\n",
    "        onde_new[index,i] = threshold\n",
    "    return onde_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "charitable-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteration on all the curves and data analysis\n",
    "\n",
    "# Prepare the resulting vectors as empty ones\n",
    "mape = np.empty((int((u_A-l_A)/np.abs(step)), 2), dtype=np.float32)\n",
    "\n",
    "# Apply all the levels of alteration\n",
    "values = range(u_A,l_A,step)\n",
    "\n",
    "for j,s in enumerate(values):    \n",
    "    # Alter all the curves\n",
    "    onde_new = peak_cut(onde_raw, s)\n",
    "\n",
    "    # Compute the parameters (5 average values) from each curve\n",
    "    params = np.empty((len(onde_new), 5), dtype=np.float32)\n",
    "    for i in range(len(onde_new)):\n",
    "        try:\n",
    "            params[i] = np.array(compute_params(onde_new[i]))\n",
    "            assert np.any(np.isnan(params[i])) == False\n",
    "        except:\n",
    "            print(\"Parameter \" + str(i) + \" cannot be computed\")\n",
    "            continue\n",
    "\n",
    "    # Test set + normalization\n",
    "    new_data  = np.concatenate([df.TBlood.values.reshape(-1,1),params], axis = 1)\n",
    "    test  = (new_data  - xmin) / (xmax - xmin)    \n",
    "\n",
    "    # Prediction using the models\n",
    "    if MODE == 0:\n",
    "        pred = model.predict(test)\n",
    "        y_pred_denorm  = denormalize(pred)\n",
    "    else:\n",
    "        # Using the parallel network as well\n",
    "        y_pred_t0 = model.predict(test)\n",
    "        y_pred_t1 = model1.predict(test)\n",
    "\n",
    "        y_pred_t0_denorm  = denormalize(y_pred_t0)\n",
    "        y_pred_t1_denorm  = denormalize(y_pred_t1)\n",
    "        y_pred_denorm = (y_pred_t0_denorm + y_pred_t1_denorm)/2\n",
    "\n",
    "    # Save the true values for evaluation\n",
    "    pO2_true = np.concatenate([df.pO2_ABL1_37.values.reshape(-1,1), df.pO2_ABL1.values.reshape(-1,1)], axis=1)\n",
    "   \n",
    "    # Compute the MAPE\n",
    "    mape[j,0]=mean_absolute_percentage_error(pO2_true[:, 0], y_pred_denorm[:, 0])\n",
    "    mape[j,1]=mean_absolute_percentage_error(pO2_true[:, 1], y_pred_denorm[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "collected-criminal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UU Robustness [Cut of the peak - Current pO2]: 0.8370370416906961\n",
      "UL Robustness [Cut of the peak - Current pO2]: 0.5246962500154823\n",
      "LU Robustness [Cut of the peak - Current pO2]: 0.9734430740850389\n",
      "LL Robustness [Cut of the peak - Current pO2]: 0.6348662952063278\n",
      "UU Robustness [Cut of the peak - pO2 at 37°]: 0.8370370416906961\n",
      "UL Robustness [Cut of the peak - pO2 at 37°]: 0.5330475809820328\n",
      "LU Robustness [Cut of the peak - pO2 at 37°]: 0.9734430740850389\n",
      "LL Robustness [Cut of the peak - pO2 at 37°]: 0.6459894651738256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-f7376d6114f0>:12: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  r = quad(integrand_b, 0, x0, args=(x0,err))\n"
     ]
    }
   ],
   "source": [
    "# Estimating the robustness w.r.t. Current pO2\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,1]\n",
    "real = mape[:,1]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Cut of the peak - Current pO2]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Cut of the peak - Current pO2]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Cut of the peak - Current pO2]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Cut of the peak - Current pO2]: '+str(ll))\n",
    "\n",
    "# Estimating the robustness w.r.t. pO2 at 37°\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,0]\n",
    "real = mape[:,0]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Cut of the peak - pO2 at 37°]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Cut of the peak - pO2 at 37°]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Cut of the peak - pO2 at 37°]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Cut of the peak - pO2 at 37°]: '+str(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cognitive-chest",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the Current pO2\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(range(4000,1300,-10)),mape[:,1], marker='x', color='blue', )\n",
    "    plt.xlabel('Cut of the peak')\n",
    "    plt.xticks(np.array(range(1300,4000,200)))\n",
    "    plt.yticks(np.array(range(3,30,2)))\n",
    "    plt.ylabel('MAPE error - current po2')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,1], c='green', label = 'nominal MAPE')\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    ax.invert_xaxis()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "covered-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the Current pO2\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(range(4000,1300,-10)),mape[:,0], marker='x', color='blue', )\n",
    "    plt.xlabel('Cut of the peak')\n",
    "    plt.xticks(np.array(range(1300,4000,200)))\n",
    "    plt.yticks(np.array(range(3,30,2)))\n",
    "    plt.ylabel('MAPE error - pO2 at 37°')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,0], c='green', label = 'nominal MAPE')\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    ax.invert_xaxis()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-ready",
   "metadata": {},
   "source": [
    "### 4. Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "typical-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration params\n",
    "l_A = 0\n",
    "u_A = 50\n",
    "theta = 10\n",
    "\n",
    "# Function to be used for introducing a gaussian noise\n",
    "def add_noise(onde_raw, standard_deviation):\n",
    "    onde_new = np.copy(onde_raw)\n",
    "    mean = 0\n",
    "    for i in range(len(onde_new)):\n",
    "        noise  = np.random.normal(mean, standard_deviation, size=onde_raw.shape[1])\n",
    "        onde_new[i,:]= onde_new[i,:] + noise\n",
    "    return onde_new  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "final-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteration on all the curves and data analysis\n",
    "\n",
    "# Prepare the resulting vectors as empty ones\n",
    "mape = np.empty(((u_A-l_A) + 1, 2), dtype=np.float32)\n",
    "\n",
    "# Apply all the levels of alteration\n",
    "for j in range((u_A-l_A) + 1):\n",
    "    onde_new = np.copy(onde_raw)\n",
    "\n",
    "    # Alter all the curves\n",
    "    onde_new = add_noise(onde_new, j)  \n",
    "\n",
    "    # Compute the parameters (5 average values) from each curve\n",
    "    params = np.empty((len(onde_new), 5), dtype=np.float32)\n",
    "    for i in range(len(onde_new)):\n",
    "        try:\n",
    "            params[i] = np.array(compute_params(onde_new[i]))\n",
    "            assert np.any(np.isnan(params[i])) == False\n",
    "        except:\n",
    "            print(\"Parameter \" + str(i) + \" cannot be computed\")\n",
    "            continue\n",
    "\n",
    "    # Test set + normalization\n",
    "    new_data  = np.concatenate([df.TBlood.values.reshape(-1,1),params], axis = 1)\n",
    "    test  = (new_data  - xmin) / (xmax - xmin)    \n",
    "\n",
    "    # Prediction using the models\n",
    "    if MODE == 0:\n",
    "        pred = model.predict(test)\n",
    "        y_pred_denorm  = denormalize(pred)\n",
    "    else:\n",
    "        # Using the parallel network as well\n",
    "        y_pred_t0 = model.predict(test)\n",
    "        y_pred_t1 = model1.predict(test)\n",
    "\n",
    "        y_pred_t0_denorm  = denormalize(y_pred_t0)\n",
    "        y_pred_t1_denorm  = denormalize(y_pred_t1)\n",
    "        y_pred_denorm = (y_pred_t0_denorm + y_pred_t1_denorm)/2\n",
    "\n",
    "    # Save the true values for evaluation\n",
    "    pO2_true = np.concatenate([df.pO2_ABL1_37.values.reshape(-1,1), df.pO2_ABL1.values.reshape(-1,1)], axis=1)\n",
    "   \n",
    "    # Compute the MAPE\n",
    "    mape[j,0]=mean_absolute_percentage_error(pO2_true[:, 0], y_pred_denorm[:, 0])\n",
    "    mape[j,1]=mean_absolute_percentage_error(pO2_true[:, 1], y_pred_denorm[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "advanced-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UU Robustness [Gaussian Noise - Current pO2]: 0.8823529411764708\n",
      "UL Robustness [Gaussian Noise - Current pO2]: 0.35418619514737565\n",
      "LU Robustness [Gaussian Noise - Current pO2]: 0.986159170159957\n",
      "LL Robustness [Gaussian Noise - Current pO2]: 0.4874877207404803\n",
      "UU Robustness [Gaussian Noise - pO2 at 37°]: 0.8431372549012515\n",
      "UL Robustness [Gaussian Noise - pO2 at 37°]: 0.3451600058231515\n",
      "LU Robustness [Gaussian Noise - pO2 at 37°]: 0.9753940788235412\n",
      "LL Robustness [Gaussian Noise - pO2 at 37°]: 0.48394339719606144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-f7376d6114f0>:12: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  r = quad(integrand_b, 0, x0, args=(x0,err))\n"
     ]
    }
   ],
   "source": [
    "# Estimating the robustness w.r.t. Current pO2\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,1]\n",
    "real = mape[:,1]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Gaussian Noise - Current pO2]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Gaussian Noise - Current pO2]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Gaussian Noise - Current pO2]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Gaussian Noise - Current pO2]: '+str(ll))\n",
    "\n",
    "# Estimating the robustness w.r.t. pO2 at 37°\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,0]\n",
    "real = mape[:,0]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Gaussian Noise - pO2 at 37°]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Gaussian Noise - pO2 at 37°]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Gaussian Noise - pO2 at 37°]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Gaussian Noise - pO2 at 37°]: '+str(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "purple-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the Current pO2\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(range(0,51,1)),mape[:,1], marker='x', color='blue', )\n",
    "    plt.xlabel('Gaussian Noise')\n",
    "    plt.xticks(np.array(range(0,51,10)))\n",
    "    plt.yticks(np.array(range(3,30,2)))\n",
    "    plt.ylabel('MAPE error - current po2')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,1], c='green', label = 'nominal MAPE')\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "loved-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the pO2 at 37°\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(range(0,51,1)),mape[:,0], marker='x', color='blue', )\n",
    "    plt.xlabel('Gaussian Noise')\n",
    "    plt.xticks(np.array(range(0,51,10)))\n",
    "    plt.yticks(np.array(range(3,30,2)))\n",
    "    plt.ylabel('MAPE error - po2 at 37°C')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,0], c='green', label = 'nominal MAPE')\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-advisory",
   "metadata": {},
   "source": [
    "### 5. Amplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "coated-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration params\n",
    "l_A = 1\n",
    "u_A = 2\n",
    "theta = 10\n",
    "step = 0.1\n",
    "\n",
    "# Function to be used for introducing an amplification alteration\n",
    "def amplification(onde_raw, amplification):\n",
    "    onde_new = np.copy(onde_raw)\n",
    "    onde_new = onde_new * (amplification)\n",
    "    return onde_new  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "municipal-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteration on all the curves and data analysis\n",
    "\n",
    "# Prepare the resulting vectors as empty ones\n",
    "mape = np.empty((int((u_A-l_A)/step) + 1, 2), dtype=np.float32)\n",
    "\n",
    "# Apply all the levels of alteration\n",
    "values = np.arange(l_A, u_A+step, step)\n",
    "\n",
    "for j,s in enumerate(values):\n",
    "    # Alter all the curves\n",
    "    onde_new = amplification(onde_raw, s)\n",
    "\n",
    "    # Compute the parameters (5 average values) from each curve\n",
    "    params = np.empty((len(onde_new), 5), dtype=np.float32)\n",
    "    for i in range(len(onde_new)):\n",
    "        try:\n",
    "            params[i] = np.array(compute_params(onde_new[i]))\n",
    "            assert np.any(np.isnan(params[i])) == False\n",
    "        except:\n",
    "            print(\"Parameter \" + str(i) + \" cannot be computed\")\n",
    "            continue\n",
    "\n",
    "    # Test set + normalization\n",
    "    new_data  = np.concatenate([df.TBlood.values.reshape(-1,1),params], axis = 1)\n",
    "    test  = (new_data  - xmin) / (xmax - xmin)    \n",
    "\n",
    "    # Prediction using the models\n",
    "    if MODE == 0:\n",
    "        pred = model.predict(test)\n",
    "        y_pred_denorm  = denormalize(pred)\n",
    "    else:\n",
    "        # Using the parallel network as well\n",
    "        y_pred_t0 = model.predict(test)\n",
    "        y_pred_t1 = model1.predict(test)\n",
    "\n",
    "        y_pred_t0_denorm  = denormalize(y_pred_t0)\n",
    "        y_pred_t1_denorm  = denormalize(y_pred_t1)\n",
    "        y_pred_denorm = (y_pred_t0_denorm + y_pred_t1_denorm)/2\n",
    "\n",
    "    # Save the true values for evaluation\n",
    "    pO2_true = np.concatenate([df.pO2_ABL1_37.values.reshape(-1,1), df.pO2_ABL1.values.reshape(-1,1)], axis=1)\n",
    "   \n",
    "    # Compute the MAPE\n",
    "    mape[j,0]=mean_absolute_percentage_error(pO2_true[:, 0], y_pred_denorm[:, 0])\n",
    "    mape[j,1]=mean_absolute_percentage_error(pO2_true[:, 1], y_pred_denorm[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "vocal-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UU Robustness [Amplification - Current pO2]: 1.0\n",
      "UL Robustness [Amplification - Current pO2]: 0.466833533003435\n",
      "LU Robustness [Amplification - Current pO2]: 1.0\n",
      "LL Robustness [Amplification - Current pO2]: 0.5299627332647221\n",
      "UU Robustness [Amplification - pO2 at 37°]: 1.0\n",
      "UL Robustness [Amplification - pO2 at 37°]: 0.452648239514975\n",
      "LU Robustness [Amplification - pO2 at 37°]: 1.0\n",
      "LL Robustness [Amplification - pO2 at 37°]: 0.5340039993213734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-f7376d6114f0>:12: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  r = quad(integrand_b, 0, x0, args=(x0,err))\n"
     ]
    }
   ],
   "source": [
    "# Estimating the robustness w.r.t. Current pO2\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,1]\n",
    "real = mape[:,1]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Amplification - Current pO2]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Amplification - Current pO2]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Amplification - Current pO2]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Amplification - Current pO2]: '+str(ll))\n",
    "\n",
    "# Estimating the robustness w.r.t. pO2 at 37°\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,0]\n",
    "real = mape[:,0]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Amplification - pO2 at 37°]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Amplification - pO2 at 37°]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Amplification - pO2 at 37°]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Amplification - pO2 at 37°]: '+str(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "contrary-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the Current pO2\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(np.arange(l_A,u_A+step,step)),mape[:,1], marker='x', color='blue', )\n",
    "    plt.xlabel('Amplification')\n",
    "    plt.xticks(np.array(np.arange(l_A,u_A+step,step)))\n",
    "    plt.yticks(np.array(np.arange(3,30,2)))\n",
    "    plt.ylabel('MAPE error - current po2')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,1], c='green', label = 'nominal MAPE')\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "protected-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the pO2 at 37°\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(np.arange(l_A,u_A+step,step)),mape[:,0], marker='x', color='blue', )\n",
    "    plt.xlabel('Amplification')\n",
    "    plt.xticks(np.array(np.arange(l_A,u_A+step,step)))\n",
    "    plt.yticks(np.array(range(3,30,2)))\n",
    "    plt.ylabel('MAPE error - po2 at 37°C')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,0], c='green', label = 'nominal MAPE')\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-modern",
   "metadata": {},
   "source": [
    "### 6. Attenuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "tribal-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration params\n",
    "l_A = 0\n",
    "u_A = 0.5\n",
    "theta = 10\n",
    "step = 0.1\n",
    "\n",
    "# Function to be used for introducing an attenuation alteration\n",
    "def attenuation(onde_raw, attenuation):\n",
    "    onde_new = np.copy(onde_raw)\n",
    "    onde_new *= (1 - attenuation)\n",
    "    return onde_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "chicken-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteration on all the curves and data analysis\n",
    "\n",
    "# Prepare the resulting vectors as empty ones\n",
    "mape = np.empty((int((u_A-l_A)/step) + 1, 2), dtype=np.float32)\n",
    "\n",
    "# Apply all the levels of alteration\n",
    "values = np.arange(l_A, u_A+step, step)\n",
    "\n",
    "for j,s in enumerate(values):\n",
    "    # Alter all the curves\n",
    "    onde_new = attenuation(onde_raw, s)\n",
    "\n",
    "    # Compute the parameters (5 average values) from each curve\n",
    "    params = np.empty((len(onde_new), 5), dtype=np.float32)\n",
    "    for i in range(len(onde_new)):\n",
    "        try:\n",
    "            params[i] = np.array(compute_params(onde_new[i]))\n",
    "            assert np.any(np.isnan(params[i])) == False\n",
    "        except:\n",
    "            print(\"Parameter \" + str(i) + \" cannot be computed\")\n",
    "            continue\n",
    "\n",
    "    # Test set + normalization\n",
    "    new_data  = np.concatenate([df.TBlood.values.reshape(-1,1),params], axis = 1)\n",
    "    test  = (new_data  - xmin) / (xmax - xmin)    \n",
    "\n",
    "    # Prediction using the models\n",
    "    if MODE == 0:\n",
    "        pred = model.predict(test)\n",
    "        y_pred_denorm  = denormalize(pred)\n",
    "    else:\n",
    "        # Using the parallel network as well\n",
    "        y_pred_t0 = model.predict(test)\n",
    "        y_pred_t1 = model1.predict(test)\n",
    "\n",
    "        y_pred_t0_denorm  = denormalize(y_pred_t0)\n",
    "        y_pred_t1_denorm  = denormalize(y_pred_t1)\n",
    "        y_pred_denorm = (y_pred_t0_denorm + y_pred_t1_denorm)/2\n",
    "\n",
    "    # Save the true values for evaluation\n",
    "    pO2_true = np.concatenate([df.pO2_ABL1_37.values.reshape(-1,1), df.pO2_ABL1.values.reshape(-1,1)], axis=1)\n",
    "   \n",
    "    # Compute the MAPE\n",
    "    mape[j,0]=mean_absolute_percentage_error(pO2_true[:, 0], y_pred_denorm[:, 0])\n",
    "    mape[j,1]=mean_absolute_percentage_error(pO2_true[:, 1], y_pred_denorm[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "economic-holocaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UU Robustness [Attenuation - Current pO2]: 1.0\n",
      "UL Robustness [Attenuation - Current pO2]: 0.43560619354248037\n",
      "LU Robustness [Attenuation - Current pO2]: 1.0\n",
      "LL Robustness [Attenuation - Current pO2]: 0.5581675291061401\n",
      "UU Robustness [Attenuation - pO2 at 37°]: 0.8333333333333333\n",
      "UL Robustness [Attenuation - pO2 at 37°]: 0.40087769031524656\n",
      "LU Robustness [Attenuation - pO2 at 37°]: 0.9722222222222224\n",
      "LL Robustness [Attenuation - pO2 at 37°]: 0.5459218462308248\n"
     ]
    }
   ],
   "source": [
    "# Estimating the robustness w.r.t. Current pO2\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,1]\n",
    "real = mape[:,1]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Attenuation - Current pO2]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Attenuation - Current pO2]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Attenuation - Current pO2]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Attenuation - Current pO2]: '+str(ll))\n",
    "\n",
    "# Estimating the robustness w.r.t. pO2 at 37°\n",
    "ideal = np.ones((mape.shape[0])) * mape[0,0]\n",
    "real = mape[:,0]\n",
    "real_shape = real.shape[0]\n",
    "ideal_shape = ideal.shape[0]\n",
    "\n",
    "heav = UU_robustness(real, theta, real_shape)\n",
    "print('UU Robustness [Attenuation - pO2 at 37°]: '+str(heav))\n",
    "basic = UL_robustness(real, theta, real_shape)\n",
    "print('UL Robustness [Attenuation - pO2 at 37°]: '+str(basic))\n",
    "weight = LU_robustness(real, theta, real_shape)\n",
    "print('LU Robustness [Attenuation - pO2 at 37°]: '+str(weight))\n",
    "ll = LL_robustness(real, theta, real_shape)\n",
    "print('LL Robustness [Attenuation - pO2 at 37°]: '+str(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "interim-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the Current pO2\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(np.arange(l_A,u_A+step,step)),mape[:,1], marker='x', color='blue', )\n",
    "    plt.xlabel('Attenuation')\n",
    "    plt.xticks(np.array(np.arange(l_A,u_A+step,step)))\n",
    "    plt.yticks(np.array(np.arange(3,30,2)))\n",
    "    plt.ylabel('MAPE error - current po2')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,1], c='green', label = 'nominal MAPE')\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "competitive-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy function between the alteration range for the pO2 at 37°\n",
    "if DEBUG is True:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    c = plt.scatter(np.array(np.arange(l_A,u_A+step,step)),mape[:,0], marker='x', color='blue', )\n",
    "    plt.xlabel('Attenuation')\n",
    "    plt.xticks(np.array(np.arange(l_A,u_A+step,step)))\n",
    "    plt.yticks(np.array(range(3,30,2)))\n",
    "    plt.ylabel('MAPE error - po2 at 37°C')\n",
    "    plt.axhline(10, c='red', label = 'upper bound')\n",
    "    plt.axhline(mape[0,0], c='green', label = 'nominal MAPE')\n",
    "\n",
    "\n",
    "    ax = c.axes\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
